{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"display_name":"Yandex DataSphere Kernel","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"notebookId":"7c29683c-86a5-421a-8a0c-90189ba53ee8"},"cells":[{"cell_type":"markdown","source":"## Оценка качества STT моделей","metadata":{"cellId":"pdi41sd9ywggooxhxy7wlp"}},{"cell_type":"markdown","source":"Качество распознавания речи на имеющихся данных сильно зависит от выбора конкретной модели. Но чтобы можно было определить, какая из моделей лучше справляется с распознаванием под конкретный бизнес-кейс, требуется правильно построить систему оценки качества распознавания и определить соответствующие метрики.\n\nНаиболее популярной метрикой при оценке качества распознавания является метрика WER (Word Error Rate). Эта метрика оценивает похожесть полученного распознавания на некоторый \"эталонный\" пример, как правило получаемый с помощью разметки аудиозаписей с помощью асессоров. Проблема заключается в том, что значение этой метрики может очень сильно варьироваться не только от результатов распознавания, но также и от качества разметки аудиозаписей и самой методологии оценки.\n\nВ качестве примера можно привести популярную фразу \"алло\", которая может быть размечена как минимум четырьмя различными способами: \"алло\", \"алле\", \"ало\", \"але\". Также качество может падать, если пытаться различать буквы \"ё\" и \"е\", которые эквивалентны с точки зрения большинства моделей распознавания. Наконец, качество может очень сильно зависеть от того, требуется ли нам различать различные формы одних и тех же слов (к примеру, род, падежи существительных, времена глаголов и т.п.).\n\nПо этой причине мы решили предоставить пользователям свою небольшую библиотеку, которая позволит использовать метрики для оценки качества распознавания с учётом описанных особенностей. На текущий момент эта библиотека поддерживает вычисление метрики WER, однако в дальнейшем библиотеку планируется расширить и другими метриками.","metadata":{"cellId":"7k58oggvwatlffly4zs7ft"}},{"cell_type":"code","source":"from stt_metrics import WER, ClusterReferences\nfrom stt_metrics.text_transform import Lemmatizer","metadata":{"cellId":"wu2sr42o5dut1a288k6yo","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Пример использования метрики WER\n\nРассмотрим самый простой вариант использования метрики WER:","metadata":{"cellId":"yc0598s63rmasktbb44rah"}},{"cell_type":"code","source":"reference = 'алло добрый день с моей карты только что списали крупную сумму денег хочу заблокировать её'\nhypothesis = 'але добрый день моей карты только что списал крупную суму денег хочу заблокировать ее'","metadata":{"cellId":"4y99e6d3ukju9e49pkxhsr","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"wer = WER()\nwer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\nwer_value = wer.calculate_metric(wer_data)","metadata":{"cellId":"lvue2l49urq33ot90clyki","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"`wer_data` &mdash; специальный объект, который хранит необходимую для вычисления WER информацию, а также предоставляет нам выравнивание двух текстов с указанием отличий. Последняя особенность может быть очень полезна при дальнейшем анализе отличий в распознавании и разметке.\n\nТак, на примере ниже мы видим, что значение метрики WER оказывается достаточно высоким. Однако многие ошибки для данного кейса оказываются довольно незначительными. Так, одна ошибка возникает из-за появившейся в разметке буквы \"ё\", ещё одна из ошибок связана с отличием в словах \"але\" и \"алло\", и ещё одна ошибка произошла из-за нераспознанного множественного числа глагола \"списал\".","metadata":{"cellId":"4m2uaxa0p3ubyimm0mwdie"}},{"cell_type":"code","source":"print(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"02las68bbbxjbfcg023x5w","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 5,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: АЛЕ  добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ЕЕ,\n  diff_ref: АЛЛО добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ЕЁ\n}\nWER: 0.3333333333333333\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Избавление от ошибок\n\n#### Удаление артефактов\n\nОт возможных ошибок первого типа довольно просто избавиться, если заранее провалидировать имеющуюся разметку аудио и избавиться от возможных артефактов. В данном случае такой препроцессинг оказывается довольно простым, хотя в общем случае артефакты могут быть и куда менее очевидными.","metadata":{"cellId":"f3bp6agkr19g0p60fawjh"}},{"cell_type":"code","source":"def remove_artifacts(text):\n    return text.replace('ё', 'е')\n\n\nhypothesis, reference = remove_artifacts(hypothesis), remove_artifacts(reference)\n\nwer = WER()\nwer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\nwer_value = wer.calculate_metric(wer_data)\n\nprint(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"sifrl68bdficokkgpze9co","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 4,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: АЛЕ  добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ее,\n  diff_ref: АЛЛО добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ее\n}\nWER: 0.26666666666666666\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"#### ClusterReferences\n\nОшибки второго типа также могут быть довольно просто исключены, если явно указать наборы синонимичных фраз (ClusterReferences), которые следует воспринимать одинаково:","metadata":{"cellId":"c7bugxl9ftudswqm68cm6p"}},{"cell_type":"code","source":"cr = ClusterReferences()\ncr.add_cluster(center='алло', aliases=['ало', 'але', 'алле'])\n\nwer = WER(cr=cr)\nwer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\nwer_value = wer.calculate_metric(wer_data)\n\nprint(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"qs4zr12523lccn6a5gsy","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 3,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: алло добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ее,\n  diff_ref: алло добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ее\n}\nWER: 0.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"#### Lemmatizer\n\nНаконец, можно также постараться избавиться и от ошибок третьего типа, если привести все имеющиеся слова к их леммам. Тем не менее, делать это также следует аккуратно, потому что в лемматизации также могут нуждаться и фразы из ClusterReferences:","metadata":{"cellId":"a23rpn5h2cn7ndxwj68c"}},{"cell_type":"code","source":"lemmatizer = Lemmatizer()\nlemm_hypothesis, lemm_reference = lemmatizer.transform(hypothesis), lemmatizer.transform(reference)\n\nwer = WER(cr=cr)\nwer_data = wer.get_metric_data(hyp=lemm_hypothesis, ref=lemm_reference)\nwer_value = wer.calculate_metric(wer_data)\n\nprint(wer_data)\nprint(f'WER: {wer_value}')","metadata":{"cellId":"8hhjier6mvskvi6ndy0j9s","trusted":true},"outputs":[{"name":"stdout","text":"{\n  errors: 2,\n  hyp_wc: 14,\n  ref_wc: 15,\n  diff_hyp: алло добрый день * мой карта только что списать крупный СУМА  деньга хотеть заблокировать она,\n  diff_ref: алло добрый день с мой карта только что списать крупный СУММА деньга хотеть заблокировать она\n}\nWER: 0.13333333333333333\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Выводы\n\nЕсли вам просто требуется проверить, что конкретная модель распознавания в среднем делает достаточно мало ошибок в словах, то простая версия метрики WER вполне может подойти вам.\n\nЕсли же вы используете эту метрику для сравнения поведения различных моделей на вашем бизнес-кейсе, то вам может также помочь:\n\n* Удаление из разметки и набор распознаваний явных артефактов, которые могут ухудшать значения используемых метрик, не влияя при этом на качество решения конкретной бизнес-задачи\n\n* Использование ClusterReference'ов для \"склейки\" одинаковых по сути распознаваний. Так можно склеить различные варианты распознавания фраз типа \"алло\", а также распознавания фраз с пробелами (наподобие \"контр страйк\" и \"контрстрайк\")\n\n* Лемматизация слов, если для нас не важны их окончания","metadata":{"cellId":"virjbqdb3crjuxif3vjlh"}},{"cell_type":"code","source":"","metadata":{"cellId":"89d2tvzxin4f1g7k4vbv5"},"outputs":[],"execution_count":null}]}